[data_generation]
n = 50
min_height = 25
max_height = 48
min_width = 25
max_width = 48
noise = 0.02
size = 500
center = True
train_size = 0.7
val_size = 0.2
test_size = 0.1

[network]
# size of input layer
input_size = 2500
# Hidden layers and output layer (not softmax)
# syntax: (number of neurons, "activation function")
layers = [(50, "tanh"), (25, "tanh"), (20, "relu"), (10, "tanh"), (4, "sigmoid")]
weight_ranges = [(-0.5,0.5), (-0.5,0.5), (-0.5,0.5), (-0.5,0.5), (-0.5,0.5)]
# softmax as additional output layer True/False
softmax = True

# Options: cross_entropy/mse
loss = cross_entropy

# Options: l1/l2/no
regularization = l2
reg_rate = 0.001

learning_rate = 0.1

[fit]
epochs = 100
metrics = ["accuracy"]
batch_size=4
verbosity=1


